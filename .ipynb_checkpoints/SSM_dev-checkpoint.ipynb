{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main data structure we rely on in this work is the self-similarity matrix. Given a space curve parameterized by the unit interval $\\gamma : [0, 1] \\to (M, d)$, a Self-Similarity Image (SSI) is a function $D : [0, 1] \\times [0, 1] \\to \\mathbb{R}$ so that\n",
    "\n",
    "$$ D_\\gamma(i, j) = d(\\gamma(i), \\gamma(j)) $$\n",
    "\n",
    "The discretized version of an SSI corresponding to a sampled version of a curve is a self-similarity matrix (SSM). SSIs and SSMs are naturally blind to isometries of the underlying space curve and time-ordered point cloud, respectively; these structures remain the same if the curve/point cloud is rotated/translated/flipped.\n",
    "\n",
    "\n",
    "Time-ordered SSMs have been applied to the problem of human activity recognition in video [20], periodicity and symmetry detection in video motion [11], musical audio note boundary detection [14], music structure understanding and segmentation [4, 23, 35, 28], cover song identification [39], and dynamical systems [29], to name a few areas. In this work, we study more general properties of time-ordered SSMs that make them useful for alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from TDA_helper_fcns import load_data, plot_gests, get_max_perf_time\n",
    "from ssm_databuild_mp import rbf_scalar_weight, L2_scalar_weight, L1_scalar_weight, build_1D_SSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdat = load_data(subjects=[\"30\", \"01\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_30_1_1 = gdat[\"30\"][\"1_0_1\"]\n",
    "tst_30_1_2 = gdat[\"30\"][\"1_0_2\"]\n",
    "tst_01_1_1 = gdat[\"01\"][\"1_0_1\"]\n",
    "tst_01_1_2 = gdat[\"01\"][\"1_0_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each list is a subject performing a gesture\n",
    "# each array in each list is a SSM for sensor reading of that gesture\n",
    "tst_30_1_1_ssm_lst = [build_1D_SSM(tst_30_1_1[:,i], L2_scalar_weight, 1) for i in range(1,9)]\n",
    "tst_30_1_2_ssm_lst = [build_1D_SSM(tst_30_1_2[:,i], L2_scalar_weight, 1) for i in range(1,9)]\n",
    "tst_01_1_1_ssm_lst = [build_1D_SSM(tst_01_1_1[:,i], L2_scalar_weight, 1) for i in range(1,9)]\n",
    "tst_01_1_2_ssm_lst = [build_1D_SSM(tst_01_1_2[:,i], L2_scalar_weight, 1) for i in range(1,9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gests(\"30\", \"1_0_1\", gdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, i in enumerate(tst_30_1_1_ssm_lst):\n",
    "    plt.imshow(i)\n",
    "    plt.title(\"Channel\"+\" \"+str(n+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gests(\"30\", \"1_0_2\", gdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, i in enumerate(tst_30_1_2_ssm_lst):\n",
    "    plt.imshow(i)\n",
    "    plt.title(\"Channel\"+\" \"+str(n+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gests(\"01\", \"1_0_1\", gdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, i in enumerate(tst_01_1_1_ssm_lst):\n",
    "    plt.imshow(i)\n",
    "    plt.title(\"Channel\"+\" \"+str(n+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gests(\"01\", \"1_0_2\", gdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, i in enumerate(tst_01_1_2_ssm_lst):\n",
    "    plt.imshow(i)\n",
    "    plt.title(\"Channel\"+\" \"+str(n+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "NOTE: shape of every channel will be the same for a given subject/ gesture combo (list), so I only need to check the first gesture of each list ($\\mathcal{O}(s)$ time where $s$ is number of subjects). However, I will have to zero pad every array ($8$) in each gesture for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdict = get_max_perf_time(gdat)\n",
    "sdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(1,10).reshape(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.pad(A, pad_width=(2,2), mode=\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
