{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from data_cube import DataCube\n",
    "from ssm import SSM\n",
    "from similarity_network_fusion import SNF, cumulated_euc_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.metrics import dtw, dtw_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DataCube(\n",
    "    subjects=\"all\",\n",
    "    gestures=[\"3\", \"4\", \"5\", \"6\"],\n",
    "    channels=[\"2\", \"4\", \"6\", \"8\"],\n",
    "    data_grp=\"parsed\"\n",
    ")\n",
    "dc.load_data()\n",
    "dc.rms_smooth(300, 20)\n",
    "dc.normalize_modalities(smooth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_synergist_channels(gnum, array):\n",
    "    \"\"\"\n",
    "    pass synergist only channels for each gesture\n",
    "    gnum - gesture number (i.e. 1, 2, 3, or 4)\n",
    "    array - entire array of all channels and time index\n",
    "    \"\"\"\n",
    "    synrgsts = {\"3\":[0, 1, 4], # channels 2 & 8; 0 is tidx\n",
    "                \"4\":[0, 2, 3], # channels 4 & 6; 0 is tidx\n",
    "                \"5\":[0, 1, 2], # channels 4 & 2; 0 is tidx\n",
    "                \"6\":[0, 3, 4]} # channels 6 & 8; 0 is tidx\n",
    "    synergist_array = np.c_[array[:, synrgsts[gnum][0]],\n",
    "                            array[:, synrgsts[gnum][1]],\n",
    "                            array[:, synrgsts[gnum][2]]]\n",
    "    return synergist_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dict_synerg = {}\n",
    "for s, gdict in dc.data_set_smooth.items():\n",
    "    print(s)\n",
    "    dict_synerg[s] = {}\n",
    "    for g, a in gdict.items():\n",
    "        snf = SNF(pass_synergist_channels(g[0], a), k=0.2, metric=cumulated_euc_ts)\n",
    "        # calculate graph weights to find knn\n",
    "        snf.calc_weights()\n",
    "        snf.normalize_weights()\n",
    "        # generate and normalize knn graphs\n",
    "        snf.calc_knn_weights()\n",
    "        snf.normalize_knn_weights()\n",
    "        # fuse graphs\n",
    "        snf.network_fusion(eta=0.2, iters=50)\n",
    "        #print(f\"subject {s}; gesture {g}\")\n",
    "        #snf.plot_template()\n",
    "        # save template to dict\n",
    "        dict_synerg[s][g] = snf.fused_similarity_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_syn = {}\n",
    "\n",
    "for s, gdict in dict_synerg.items():\n",
    "    decomp_syn[s] = {}\n",
    "    for g, a in gdict.items():\n",
    "        #print(f\"subject {s}; gesture {g}; avg {a.mean()}; sd {a.std()}\")\n",
    "        evals, evecs = la.eig(a)\n",
    "        evals = evals.real\n",
    "        sort_idx = np.argsort(-evals)\n",
    "        evals = evals[sort_idx]\n",
    "        evecs = evecs[:, sort_idx]\n",
    "        # calc percent of variance explained\n",
    "        #print(f\"subject {s}; gesture {g}; PoV: {evals[0].real / evals.real.sum()}\")\n",
    "        # do PCA\n",
    "        res = a @ evecs[:, 0]\n",
    "        res = scale(res.real)\n",
    "        decomp_syn[s][g] = res\n",
    "        # plot results\n",
    "        plt.subplot(211)\n",
    "        plt.plot(dc.data_set_smooth[s][g][:,0], res)\n",
    "        plt.subplot(212)\n",
    "        plt.plot(dc.data_set_smooth[s][g][:,0], dc.data_set_smooth[s][g][:,1])\n",
    "        plt.plot(dc.data_set_smooth[s][g][:,0], dc.data_set_smooth[s][g][:,2])\n",
    "        plt.plot(dc.data_set_smooth[s][g][:,0], dc.data_set_smooth[s][g][:,3])\n",
    "        plt.plot(dc.data_set_smooth[s][g][:,0], dc.data_set_smooth[s][g][:,4])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_lab = []\n",
    "gest_lab = []\n",
    "arrays = []\n",
    "\n",
    "for s, gdict in decomp_syn.items():\n",
    "    for g, a in gdict.items():\n",
    "        subj_lab.append(s)\n",
    "        gest_lab.append(int(g[0]))\n",
    "        arrays.append(a)\n",
    "\n",
    "\n",
    "predicts = []\n",
    "for n, g1 in enumerate(arrays):\n",
    "    g1_dists = []\n",
    "    for m, g2 in enumerate(arrays):\n",
    "        dist = cumulated_euc_ts(g1, g2)\n",
    "        g1_dists.append(dist)\n",
    "    g1_dists = np.array(g1_dists)\n",
    "    pred_idx = np.argsort(g1_dists)[1] # index of 2nd closest array by dtw; 1st closest is self\n",
    "    predicts.append(gest_lab[pred_idx])\n",
    "\n",
    "acc = (sum(np.array(gest_lab) == np.array(predicts)) / len(gest_lab)) * 100\n",
    "\n",
    "print(f\"accuracy: {acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize vectors by gesture\n",
    "gest_dict = {\"3\":[], \"4\":[], \"5\":[], \"6\":[]}\n",
    "\n",
    "for s, gdict in decomp_syn.items():\n",
    "    for g, a in gdict.items():\n",
    "        if g[0] not in [\"3\", \"4\", \"5\", \"6\"]: continue\n",
    "        gest_dict[g[0]].append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_dict = {\"3\":{\"3\":[], \"4\":[], \"5\":[], \"6\":[]},\n",
    "             \"4\":{\"3\":[], \"4\":[], \"5\":[], \"6\":[]},\n",
    "             \"5\":{\"3\":[], \"4\":[], \"5\":[], \"6\":[]},\n",
    "             \"6\":{\"3\":[], \"4\":[], \"5\":[], \"6\":[]}}\n",
    "\n",
    "for g1 in [\"3\", \"4\", \"5\", \"6\"]:\n",
    "    for g2 in [\"3\", \"4\", \"5\", \"6\"]:\n",
    "        for i in range(144):\n",
    "            for j in range(144):\n",
    "                if i == j and g1 == g2: continue\n",
    "                comp_dict[g1][g2].append(dtw(gest_dict[g1][i], gest_dict[g2][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g1 in [\"3\", \"4\", \"5\", \"6\"]:\n",
    "    print(f\"gesture {g1} dtw similarities w/ other gestures:\")\n",
    "    for g2 in [\"3\", \"4\", \"5\", \"6\"]:\n",
    "        print(f\"avg similarity vs gesture {g2}: {np.mean(comp_dict[g1][g2])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ripser import ripser, lower_star_img\n",
    "from persim import plot_diagrams, PersImage, bottleneck\n",
    "from TDA_helper_fcns import sublevel_set_time_series_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_lab = []\n",
    "gest_lab = []\n",
    "arrays = []\n",
    "\n",
    "for s, gdict in dict_synerg.items():\n",
    "    for g, a in gdict.items():\n",
    "        subj_lab.append(s)\n",
    "        gest_lab.append(int(g[0]))\n",
    "        arrays.append(a)\n",
    "\n",
    "# calculate bottleneck distance between all pds and make predictions\n",
    "predicts = []\n",
    "for n, g1 in enumerate(arrays):\n",
    "    dgm1 = lower_star_img(g1)\n",
    "    g1_bottlenecks = []\n",
    "    for m, g2 in enumerate(arrays):\n",
    "        dgm2 = lower_star_img(g2)\n",
    "        distance_bottleneck, (matching, D) = bottleneck(dgm1, dgm2, matching=True)\n",
    "        g1_bottlenecks.append(distance_bottleneck)\n",
    "    g1_bottlenecks = np.array(g1_bottlenecks)\n",
    "    pred_idx = np.argsort(g1_bottlenecks)[1] # index of 2nd closest array by dtw; 1st closest is self\n",
    "    predicts.append(gest_lab[pred_idx])\n",
    "\n",
    "acc = (sum(np.array(gest_lab) == np.array(predicts)) / len(gest_lab)) * 100\n",
    "\n",
    "print(f\"accuracy: {acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_lab = []\n",
    "gest_lab = []\n",
    "arrays = []\n",
    "\n",
    "for s, gdict in decomp_syn.items():\n",
    "    for g, a in gdict.items():\n",
    "        subj_lab.append(s)\n",
    "        gest_lab.append(int(g[0]))\n",
    "        arrays.append(a)\n",
    "\n",
    "# calculate bottleneck distance between all pds and make predictions\n",
    "predicts = []\n",
    "for n, g1 in enumerate(arrays):\n",
    "    rips = Rips(maxdim=0, verbose=False) # initialize rips complex\n",
    "    sls1 = sublevel_set_time_series_dist(g1)\n",
    "    dgm1 = rips.fit_transform(sls1, distance_matrix=True)[0]\n",
    "    g1_bottlenecks = []\n",
    "    for m, g2 in enumerate(arrays):\n",
    "        sls2 = sublevel_set_time_series_dist(g2)\n",
    "        dgm2 = rips.fit_transform(sls2, distance_matrix=True)[0]\n",
    "        distance_bottleneck, (matching, D) = bottleneck(dgm1, dgm2, matching=True)\n",
    "        g1_bottlenecks.append(distance_bottleneck)\n",
    "    g1_bottlenecks = np.array(g1_bottlenecks)\n",
    "    pred_idx = np.argsort(g1_bottlenecks)[1] # index of 2nd closest array by dtw; 1st closest is self\n",
    "    predicts.append(gest_lab[pred_idx])\n",
    "\n",
    "acc = (sum(np.array(gest_lab) == np.array(predicts)) / len(gest_lab)) * 100\n",
    "\n",
    "print(f\"accuracy: {acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rips = Rips(maxdim=2, verbose=False)\n",
    "pim = PersImage(pixels=[px,px], spread=sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate persistence diagrams and convert to pim\n",
    "# 1 cycles\n",
    "subj_lab = []\n",
    "gest_lab = []\n",
    "arrays = []\n",
    "\n",
    "px = 20\n",
    "sd = 0.5\n",
    "\n",
    "for s, gdict in dict_synerg.items():\n",
    "    for g, a in gdict.items():\n",
    "        subj_lab.append(s)\n",
    "        gest_lab.append(int(g[0]))\n",
    "        # initialize rips complex and persistence image object\n",
    "        rips = Rips(maxdim=1, verbose=False)\n",
    "        pim = PersImage(pixels=[px,px], spread=sd, verbose=False)\n",
    "        # calculate persistence diagram\n",
    "        dgm = rips.fit_transform(a, distance_matrix=True)\n",
    "        pim_vec = pim.transform(dgm[1])\n",
    "        arrays.append(pim_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = []\n",
    "for n, g1 in enumerate(arrays):\n",
    "    g1_dists = []\n",
    "    for m, g2 in enumerate(arrays):\n",
    "        g1_dists.append(la.norm(g1 - g2))\n",
    "    pred_idx = np.argsort(g1_dists)[1] # index of 2nd closest array by dtw; 1st closest is self\n",
    "    predicts.append(gest_lab[pred_idx])\n",
    "\n",
    "acc = (sum(np.array(gest_lab) == np.array(predicts)) / len(gest_lab)) * 100\n",
    "\n",
    "print(f\"accuracy: {acc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5,10):\n",
    "    print(gest_lab[i])\n",
    "    plt.imshow(arrays[i].reshape(px, px))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
