{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from data_cube import DataCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.metrics import dtw, dtw_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DataCube(\n",
    "    subjects=\"all\",\n",
    "    gestures=[\"3\", \"4\", \"5\", \"6\"],\n",
    "    channels=[\"2\", \"4\", \"6\", \"8\"],\n",
    "    data_grp=\"parsed\"\n",
    ")\n",
    "dc.load_data()\n",
    "dc.rms_smooth(100, 50)\n",
    "dc.normalize_modalities(smooth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Matching with Dynamic Time Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_lab = []\n",
    "gest_lab = []\n",
    "arrays = []\n",
    "\n",
    "for chan in [1,2,3,4]:\n",
    "    # get arrays of only one channel\n",
    "    for s, gdict in dc.data_set_smooth.items():\n",
    "        for g, a in gdict.items():\n",
    "            subj_lab.append(s)\n",
    "            gest_lab.append(int(g[0]))\n",
    "            arrays.append(a[:, chan])\n",
    "\n",
    "    # calculate dtw between all arrays and make predictions\n",
    "    predicts = []\n",
    "    for n, g1 in enumerate(arrays):\n",
    "        g1_dtws = []\n",
    "        for m, g2 in enumerate(arrays):\n",
    "            g1_dtws.append(dtw(g1, g2))\n",
    "        g1_dtws = np.array(g1_dtws)\n",
    "        pred_idx = np.argsort(g1_dtws)[1] # index of 2nd closest array by dtw; 1st closest is self\n",
    "        predicts.append(gest_lab[pred_idx])\n",
    "\n",
    "    acc = (sum(np.array(gest_lab) == np.array(predicts)) / len(gest_lab)) * 100\n",
    "    \n",
    "    print(f\"raw channel {chan} accuracy: {acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Matching with Cumulated Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulated_euc_ts(i, j):\n",
    "    \"\"\"\n",
    "    cumulated version of the time series w/ euclidean distance\n",
    "    in which we take the sum values over time as time increases\n",
    "    and then apply the chosen metric.\n",
    "    i, j - arrays of data points\n",
    "    \"\"\"\n",
    "    # abs equivalent to ((i-j)**2)**0.5 in scalar case\n",
    "    return abs(i.sum() - j.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_lab = []\n",
    "gest_lab = []\n",
    "arrays = []\n",
    "\n",
    "for chan in [1,2,3,4]:\n",
    "    # get arrays of only one channel\n",
    "    for s, gdict in dc.data_set_smooth.items():\n",
    "        for g, a in gdict.items():\n",
    "            subj_lab.append(s)\n",
    "            gest_lab.append(int(g[0]))\n",
    "            arrays.append(a[:, chan])\n",
    "\n",
    "    # calculate dtw between all arrays and make predictions\n",
    "    predicts = []\n",
    "    for n, g1 in enumerate(arrays):\n",
    "        g1_dtws = []\n",
    "        for m, g2 in enumerate(arrays):\n",
    "            g1_dtws.append(cumulated_euc_ts(g1, g2))\n",
    "        g1_dtws = np.array(g1_dtws)\n",
    "        pred_idx = np.argsort(g1_dtws)[1] # index of 2nd closest array by dtw; 1st closest is self\n",
    "        predicts.append(gest_lab[pred_idx])\n",
    "\n",
    "    acc = (sum(np.array(gest_lab) == np.array(predicts)) / len(gest_lab)) * 100\n",
    "    \n",
    "    print(f\"raw channel {chan} accuracy: {acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Matching with bottleneck distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ripser import lower_star_img, Rips\n",
    "from persim import plot_diagrams, PersImage, bottleneck\n",
    "from TDA_helper_fcns import sublevel_set_time_series_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "raw channel 1 accuracy: 23.09027777777778%\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "raw channel 2 accuracy: 24.04513888888889%\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "raw channel 3 accuracy: 24.71064814814815%\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "raw channel 4 accuracy: 24.82638888888889%\n"
     ]
    }
   ],
   "source": [
    "subj_lab = []\n",
    "gest_lab = []\n",
    "arrays = []\n",
    "\n",
    "rips = Rips(maxdim=0, verbose=False) # initialize rips complex\n",
    "\n",
    "for chan in [1,2,3,4]:\n",
    "    # get arrays of only one channel\n",
    "    for s, gdict in dc.data_set_smooth.items():\n",
    "        for g, a in gdict.items():\n",
    "            subj_lab.append(s)\n",
    "            gest_lab.append(int(g[0]))\n",
    "            arrays.append(a[:, chan])\n",
    "\n",
    "    # calculate bottleneck distance between all pds and make predictions\n",
    "    predicts = []\n",
    "    for n, g1 in enumerate(arrays):\n",
    "        if n % 100 == 0: print(n)\n",
    "        sls1 = sublevel_set_time_series_dist(g1)\n",
    "        dgm1 = rips.fit_transform(sls1, distance_matrix=True)[0]\n",
    "        g1_bottlenecks = []\n",
    "        for m, g2 in enumerate(arrays):\n",
    "            sls2 = sublevel_set_time_series_dist(g2)\n",
    "            dgm2 = rips.fit_transform(sls2, distance_matrix=True)[0]\n",
    "            distance_bottleneck, (matching, D) = bottleneck(dgm1, dgm2, matching=True)\n",
    "            g1_bottlenecks.append(distance_bottleneck)\n",
    "        g1_bottlenecks = np.array(g1_bottlenecks)\n",
    "        pred_idx = np.argsort(g1_bottlenecks)[1] # index of 2nd closest array by dtw; 1st closest is self\n",
    "        predicts.append(gest_lab[pred_idx])\n",
    "\n",
    "    acc = (sum(np.array(gest_lab) == np.array(predicts)) / len(gest_lab)) * 100\n",
    "    \n",
    "    print(f\"raw channel {chan} accuracy: {acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
