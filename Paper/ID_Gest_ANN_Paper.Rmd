---
title: "Identifying Hand Gestures through Myographic Signals via ANN"
author: "Sam Voisin, Eduardo Coronado, Sebastian Knigge, Yuan Zheng"
date: "April 25, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Abstract


## Introduction

Recent advances in surface electromyographic signal (sEMG) recordingsystems and analytics methods have encouraged the use of sEMGs in human-machine interfaces to control exoskeletons and protheses; however, challenges remain. Accurate classification of user movements is highly variable given the inherent noise of sEMG recording systems and per-user variability. In turn, this leads to problems downstream when attempting to convert these classifications into spatial directions (e.g. up, down, right, and left). Here, we aim to address the former challenge specifically. Our goal is to design and implement a light-weight unsupervised learning model via a multi-layered neural network to accurately identify six distinct hand gestures from sEMG data.


## Methods

Our analysis workflow was comprised of 4 main phases: preprocessing, dimension reduction via PCA, modeling, and performance comparison as shown in Figure $1$.

![Figure 1: Schematic of overall workflow stages: preprocessing, PCA, modeling and performance comparison](/Graphics/Flow.png)

### Data Preprocessing

We implemented a root means squared (RMS) envelope of $200$ ms overlapping time windows at $100$ $ms$ steps via the biosignalEMG R package to remove some of the noise generated during sEMG signal collection.

![Figure 2: sEMG data before and after RMS envelope](/Graphics/smooth_ex.png)

### Dimension Reduction

Dimension reduction was done via a principal component analysis (PCA) of the 8 distinct channels used to record sEMG data in order to reduce the training time of the neuronal network. We achieved this via the R `princomp` function that performs a spectral decomposition of the gesture design matrix.

### Modeling

The final step of preprocessing requires adding "padding" to the end of each gesture's data matrix. This is done so that the vectors passed into the models are of equal dimension. We then developed two Artificial Neural Networks (ANN), one with all components and a second with a subset selected during the dimension reduction stage (figure $3$). Each of these has a single hidden layer with eight hidden nodes having linear activation. These eight nodes feed into six output nodes with a soft-max activation function. This model was inspired by Lobov et al ($2018$).

![Figure 3a: Schematic of input hidden and classification layers of ANN with all 8 channels as input](/Graphics/1-layer-NN.png)

![Figure 3b: Schematic of input hidden and classification layers of ANN with 4 principle components as input](/Graphics/1-layer-PCA-NN.png)

To create the computation graphs for the ANN we used the R implementation of Keras which relies on Google's TensorFlow engine for backpropogation. This allows us to add, edit, and remove layers from our models as needed during the development process. The flexibility of this modular design means we are able to prototype new models quickly.

*Train/Test Sets and Performance:*

To assess the performance of each ANN, we used an $80/20$ split our data to generate a gesture-specific training and a testing sets. These were done automatically in the Keras package via random sampling. We then assessed the classifcation accuracy of each ANN using a categorical cross entropy metric which measures the *Kullback-Leibler* (KL) divergence between the true distribution of the response variable and the distribution of the predictions.

## Results


### PCA Analysis

Using the spectral decomposition we found that only $4$ of the $8$ principal components in our dataset contributed meaningfully to variance in our response. From figure $3$, we can see that these $4$ components account for approximately $80%$ of the variability we are seeking to model.

![Figure 3: PCA Screeplot and cumulutive variance plot](/Graphics/PCA_Plots/PCA_screeplot-150dpi.png)

By reducing the number of inputs from $8$ smoothed signals to only $4$ principle components, we were able to reduce overfitting in our model prior to ultizing any dropout layers. This reduction in overfitting decreased prediction accuracy in the validation data set only slightly see the *ANN Performance Comparison* section.


### ANN Performance Comparison

**Predictive Accuracy Using $8$ Smoothed Channels**


**Predictive Accuracy Using $4$ Principle Components**


![Figure 4: Accuracy ratio over epochs on training (blue) and validation (grean) data](/Graphics/[INSERT PIC])


## References & Citations

*Sergey Lobov, Nadia Krilova, I. K. V. K. and V. A. Makarov (2018). Latent factors limiting the performance of semg-interfaces. Sensors 18(1122).*

*Allaire, JJ, et al. “R Interface to 'Keras'.” R Interface to 'Keras' • Keras, RStudio &amp; Google, keras.rstudio.com*

*Goodfellow, Ian, et al. Deep Learning. MIT Press, 2016.*


















